# Database Pattern Recognition Guide

## ğŸ—„ï¸ **Decision Tree for Database Pattern Selection**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DATABASE PATTERN DECISION TREE                      â”‚
â”‚                    "Choose Your Data Weapon Wisely"                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. What is your data access pattern?
   â”œâ”€â”€â”€ OLTP (Transactional) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º ACID-compliant RDBMS
   â”œâ”€â”€â”€ OLAP (Analytical) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Data warehouse/Columnar
   â”œâ”€â”€â”€ Key-Value (Simple lookups) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º NoSQL Key-Value stores
   â”œâ”€â”€â”€ Document (Complex objects) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Document databases
   â”œâ”€â”€â”€ Graph (Relationships) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Graph databases
   â”œâ”€â”€â”€ Time Series (Metrics/Logs) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Time series databases
   â”œâ”€â”€â”€ Search (Full-text) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Search engines
   â””â”€â”€â”€ Cache (Fast access) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º In-memory databases

2. What are your scalability requirements?
   â”œâ”€â”€â”€ Single Server â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Monolithic databases
   â”œâ”€â”€â”€ Read Scaling â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Read replicas
   â”œâ”€â”€â”€ Write Scaling â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Sharding
   â”œâ”€â”€â”€ Global Distribution â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Multi-region replication
   â”œâ”€â”€â”€ Hybrid Cloud â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Federation
   â””â”€â”€â”€ Edge Computing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Edge databases

3. What are your consistency requirements?
   â”œâ”€â”€â”€ Strong Consistency â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º ACID, Paxos, Raft
   â”œâ”€â”€â”€ Eventual Consistency â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º BASE, Dynamo-style
   â”œâ”€â”€â”€ Causal Consistency â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Vector clocks, RIFL
   â”œâ”€â”€â”€ Session Consistency â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Monotonic reads
   â”œâ”€â”€â”€ Bounded Staleness â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Version vectors
   â””â”€â”€â”€ No Consistency â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Best effort

4. What is your data structure complexity?
   â”œâ”€â”€â”€ Simple Key-Value â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º LSM-tree, Hash tables
   â”œâ”€â”€â”€ Relational Data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º B-tree, R-tree
   â”œâ”€â”€â”€ Time Series â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Compressed columnar
   â”œâ”€â”€â”€ Graph Data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Adjacency lists
   â”œâ”€â”€â”€ Text/Document â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Inverted indexes
   â”œâ”€â”€â”€ Spatial Data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º R-tree, Quad-tree
   â””â”€â”€â”€ Streaming Data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Circular buffers

5. What are your performance requirements?
   â”œâ”€â”€â”€ Low Latency (<10ms) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º In-memory, SSD storage
   â”œâ”€â”€â”€ High Throughput â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Batch processing, async writes
   â”œâ”€â”€â”€ Predictable Performance â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Real-time scheduling
   â”œâ”€â”€â”€ Burst Capacity â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Auto-scaling, buffering
   â””â”€â”€â”€ Cost Optimization â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Tiered storage, compression

6. What are your operational requirements?
   â”œâ”€â”€â”€ High Availability â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Multi-zone replication
   â”œâ”€â”€â”€ Disaster Recovery â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Cross-region backup
   â”œâ”€â”€â”€ Data Compliance â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Encryption, audit trails
   â”œâ”€â”€â”€ Operational Simplicity â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Managed services
   â””â”€â”€â”€ Custom Logic â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Stored procedures, triggers
```

## ğŸ“Š **Performance Characteristics**

| Database Pattern | Best For | Read Latency | Write Latency | Scalability |
|------------------|----------|--------------|---------------|-------------|
| **B-Tree Storage** | OLTP | 1-10ms | 1-10ms | Moderate |
| **LSM-Tree Storage** | Write-Heavy | 5-50ms | 0.1-1ms | High |
| **Columnar Storage** | Analytics | 10-100ms | 100-1000ms | Very High |
| **In-Memory** | Caching | 0.01-1ms | 0.01-1ms | Limited |
| **Distributed Hash** | Key-Value | 1-5ms | 1-5ms | Very High |
| **Document Store** | JSON/XML | 1-10ms | 1-10ms | High |
| **Graph Database** | Relationships | 5-50ms | 5-50ms | Moderate |

## ğŸ¯ **Pattern Variants by Database Domain**

### **Storage Engine Patterns** ğŸ’¾
```cpp
// B-Tree Storage Engine
class BTreeStorageEngine {
    struct BTreeNode {
        bool is_leaf;
        std::vector<Key> keys;
        std::vector<Value> values;  // Only for leaf nodes
        std::vector<BTreeNode*> children;
    };

    BTreeNode* root_;
    size_t order_;  // Maximum keys per node

    Value* find(const Key& key) {
        return search_node(root_, key);
    }

    void insert(const Key& key, const Value& value) {
        if (root_->keys.size() == 2 * order_ - 1) {
            auto new_root = new BTreeNode();
            new_root->children.push_back(root_);
            split_child(new_root, 0);
            root_ = new_root;
        }
        insert_non_full(root_, key, value);
    }
};
```

### **Query Optimization Patterns** ğŸ”
```cpp
// Cost-Based Query Optimizer
class QueryOptimizer {
    struct QueryPlan {
        double cost;
        std::vector<Operator> operators;
        std::vector<IndexUsage> indexes;
    };

    QueryPlan optimize_query(const Query& query) {
        // 1. Parse query into logical operators
        auto logical_plan = parse_logical_plan(query);

        // 2. Generate physical execution plans
        auto physical_plans = generate_physical_plans(logical_plan);

        // 3. Estimate costs for each plan
        for (auto& plan : physical_plans) {
            plan.cost = estimate_cost(plan);
        }

        // 4. Select best plan
        return *std::min_element(physical_plans.begin(), physical_plans.end(),
                               [](const QueryPlan& a, const QueryPlan& b) {
                                   return a.cost < b.cost;
                               });
    }

    double estimate_cost(const QueryPlan& plan) {
        double cost = 0;
        for (const auto& op : plan.operators) {
            cost += estimate_operator_cost(op);
        }
        return cost;
    }
};
```

### **Indexing Strategies** ğŸ“‡
```cpp
// Adaptive Indexing System
class AdaptiveIndexManager {
    struct IndexStats {
        std::string column;
        size_t selectivity;      // 0-100, higher = more selective
        size_t usage_count;      // How often this index is used
        size_t maintenance_cost; // Cost to maintain index
        std::chrono::steady_clock::time_point last_used;
    };

    std::unordered_map<std::string, IndexStats> index_stats_;

    void analyze_workload(const Query& query) {
        // Track which indexes are used
        for (const auto& index : query.used_indexes) {
            index_stats_[index.name].usage_count++;
            index_stats_[index.name].last_used = std::chrono::steady_clock::now();
        }
    }

    std::vector<std::string> recommend_indexes() {
        std::vector<std::pair<double, std::string>> recommendations;

        for (const auto& [name, stats] : index_stats_) {
            // Calculate benefit/cost ratio
            double benefit = stats.selectivity * stats.usage_count;
            double cost = stats.maintenance_cost;
            double ratio = benefit / cost;

            recommendations.emplace_back(ratio, name);
        }

        // Sort by benefit/cost ratio
        std::sort(recommendations.rbegin(), recommendations.rend());

        std::vector<std::string> result;
        for (const auto& rec : recommendations) {
            result.push_back(rec.second);
        }

        return result;
    }
};
```

### **Transaction Management** ğŸ”„
```cpp
// Multi-Version Concurrency Control (MVCC)
class MVCCTransactionManager {
    struct Version {
        TransactionId transaction_id;
        Timestamp timestamp;
        std::string data;
        Version* next;  // Linked list of versions
    };

    struct Transaction {
        TransactionId id;
        IsolationLevel isolation;
        Timestamp start_time;
        std::unordered_set<std::string> read_set;
        std::unordered_set<std::string> write_set;
        TransactionState state;
    };

    std::unordered_map<std::string, Version*> version_chains_;
    std::unordered_map<TransactionId, Transaction> active_transactions_;

    bool check_conflict(const Transaction& tx1, const Transaction& tx2) {
        // Check for write-write conflicts
        for (const auto& key : tx1.write_set) {
            if (tx2.write_set.count(key)) return true;
        }

        // Check for read-write conflicts based on isolation level
        if (tx1.isolation >= IsolationLevel::READ_COMMITTED) {
            for (const auto& key : tx1.read_set) {
                if (tx2.write_set.count(key)) return true;
            }
        }

        return false;
    }

    Version* get_visible_version(const std::string& key, TransactionId tx_id) {
        auto* version = version_chains_[key];
        while (version) {
            if (is_visible(version, tx_id)) {
                return version;
            }
            version = version->next;
        }
        return nullptr;
    }
};
```

### **Replication Patterns** ğŸ”„
```cpp
// Multi-Primary Replication
class MultiPrimaryReplication {
    struct ReplicationNode {
        NodeId id;
        std::string endpoint;
        ReplicationRole role;  // PRIMARY, SECONDARY, ARBITER
        Timestamp last_sync;
        std::unordered_map<std::string, VersionVector> version_vectors;
    };

    std::vector<ReplicationNode> nodes_;
    ConflictResolver* conflict_resolver_;

    void replicate_write(const std::string& key, const std::string& value,
                        const VersionVector& version) {
        // 1. Write locally
        write_local(key, value, version);

        // 2. Replicate to all primaries
        for (const auto& node : nodes_) {
            if (node.role == ReplicationRole::PRIMARY && node.id != local_node_id_) {
                replicate_to_node(node, key, value, version);
            }
        }

        // 3. Wait for acknowledgments (quorum)
        wait_for_quorum_acknowledgments();
    }

    void handle_conflict(const std::string& key,
                        const std::vector<ConflictingValue>& conflicts) {
        auto resolved = conflict_resolver_->resolve(key, conflicts);
        apply_resolved_value(key, resolved);
    }
};
```

### **Sharding Patterns** ğŸ§©
```cpp
// Consistent Hashing Sharding
class ConsistentHashSharding {
    struct Shard {
        ShardId id;
        std::string endpoint;
        size_t capacity;
        size_t load;
    };

    std::vector<Shard> shards_;
    std::unordered_map<size_t, ShardId> hash_ring_;
    size_t virtual_nodes_per_shard_;

    ShardId get_shard_for_key(const std::string& key) {
        size_t hash = std::hash<std::string>{}(key);

        // Find the first shard with hash >= key_hash
        auto it = hash_ring_.lower_bound(hash);
        if (it == hash_ring_.end()) {
            // Wrap around to first shard
            it = hash_ring_.begin();
        }

        return it->second;
    }

    void add_shard(const Shard& shard) {
        for (size_t i = 0; i < virtual_nodes_per_shard_; ++i) {
            size_t virtual_hash = hash_function(shard.id, i);
            hash_ring_[virtual_hash] = shard.id;
        }
        shards_.push_back(shard);
    }

    void rebalance() {
        // Identify overloaded shards
        std::vector<ShardId> overloaded;
        for (const auto& shard : shards_) {
            if (shard.load > shard.capacity * 0.8) {
                overloaded.push_back(shard.id);
            }
        }

        // Migrate data from overloaded shards
        for (const auto& shard_id : overloaded) {
            migrate_data_from_shard(shard_id);
        }
    }
};
```

## ğŸ† **Real-World Production Examples**

### **Storage Engines**
- **InnoDB (MySQL)**: B-tree with MVCC and crash recovery
- **WiredTiger (MongoDB)**: LSM-tree with compression and concurrency
- **RocksDB**: LSM-tree optimized for SSDs and embedded use
- **LevelDB**: Simple LSM-tree for embedded applications
- **Cassandra SSTables**: Immutable SSTables with compaction

### **Query Optimizers**
- **PostgreSQL Optimizer**: Cost-based with genetic algorithm search
- **MySQL Optimizer**: Rule-based with cost estimation
- **Spark Catalyst**: Functional programming approach
- **Presto Optimizer**: Distributed query optimization
- **ClickHouse**: Vectorized query execution

### **Indexing Systems**
- **PostgreSQL B-tree**: Balanced tree with versioning
- **MongoDB Compound Indexes**: Multi-key indexes with intersection
- **Elasticsearch Inverted Index**: Full-text search with analyzers
- **Redis Sorted Sets**: Skip list-based range queries
- **Apache Lucene**: Segment-based inverted indexes

### **Transaction Managers**
- **PostgreSQL MVCC**: Multi-version concurrency control
- **MySQL InnoDB**: Lock-based with MVCC support
- **CockroachDB**: Distributed transactions with Raft
- **TiDB**: Percolator-based distributed transactions
- **FoundationDB**: Layered architecture with ACID

### **Replication Systems**
- **MySQL Replication**: Asynchronous and semi-sync modes
- **PostgreSQL Streaming Replication**: WAL-based log shipping
- **MongoDB Replica Sets**: Automatic failover with oplog
- **Cassandra Replication**: Consistent hashing with replication factor
- **CouchDB Replication**: Eventual consistency with conflict resolution

### **Sharding Solutions**
- **MySQL Sharding**: Application-level or proxy-based
- **MongoDB Sharding**: Config servers with chunk migration
- **Elasticsearch Sharding**: Primary/replica with rebalancing
- **Redis Cluster**: Hash slot-based sharding
- **Apache Kafka Partitioning**: Key-based partitioning with ISR

### **Caching Layers**
- **Redis**: In-memory data structures with persistence
- **Memcached**: Simple key-value cache with LRU
- **Caffeine**: Java in-memory caching with statistics
- **Ehcache**: Enterprise caching with clustering
- **Apache Ignite**: Distributed in-memory computing

## âš¡ **Performance Optimizations**

### **1. Buffer Pool Management**
```cpp
class AdaptiveBufferPool {
    struct BufferFrame {
        PageId page_id;
        char* data;
        bool is_dirty;
        std::chrono::steady_clock::time_point last_access;
        std::mutex latch;
    };

    std::unordered_map<PageId, BufferFrame*> buffer_pool_;
    std::list<PageId> lru_list_;  // For LRU eviction
    std::mutex pool_mutex_;
    size_t max_frames_;

    BufferFrame* get_page(PageId page_id) {
        std::unique_lock<std::mutex> lock(pool_mutex_);

        // Check if page is in buffer pool
        auto it = buffer_pool_.find(page_id);
        if (it != buffer_pool_.end()) {
            // Move to front of LRU list
            update_lru(it->second);
            return it->second;
        }

        // Page not in pool, need to load it
        BufferFrame* frame = find_victim_frame();
        if (frame->is_dirty) {
            flush_page(frame);
        }

        load_page_from_disk(frame, page_id);
        buffer_pool_[page_id] = frame;
        update_lru(frame);

        return frame;
    }

    void update_lru(BufferFrame* frame) {
        // Remove from current position and add to front
        lru_list_.remove(frame->page_id);
        lru_list_.push_front(frame->page_id);
    }
};
```

### **2. Query Result Caching**
```cpp
class QueryCache {
    struct CacheEntry {
        std::string query_hash;
        std::vector<std::string> result;
        std::chrono::steady_clock::time_point created;
        size_t access_count;
        std::chrono::steady_clock::time_point last_access;
    };

    std::unordered_map<std::string, CacheEntry> cache_;
    std::mutex cache_mutex_;
    size_t max_entries_;
    std::chrono::seconds ttl_;

    std::optional<std::vector<std::string>> get_cached_result(const std::string& query) {
        std::unique_lock<std::mutex> lock(cache_mutex_);

        std::string query_hash = hash_query(query);
        auto it = cache_.find(query_hash);

        if (it != cache_.end()) {
            auto& entry = it->second;

            // Check TTL
            auto now = std::chrono::steady_clock::now();
            if (now - entry.created > ttl_) {
                cache_.erase(it);
                return std::nullopt;
            }

            // Update access statistics
            entry.access_count++;
            entry.last_access = now;

            return entry.result;
        }

        return std::nullopt;
    }

    void cache_result(const std::string& query, const std::vector<std::string>& result) {
        std::unique_lock<std::mutex> lock(cache_mutex_);

        // Evict if cache is full (simple random eviction)
        if (cache_.size() >= max_entries_) {
            auto it = cache_.begin();
            std::advance(it, rand() % cache_.size());
            cache_.erase(it);
        }

        std::string query_hash = hash_query(query);
        CacheEntry entry{
            query_hash, result, std::chrono::steady_clock::now(), 0,
            std::chrono::steady_clock::now()
        };

        cache_[query_hash] = entry;
    }
};
```

### **3. Connection Pooling**
```cpp
class ConnectionPool {
    struct PooledConnection {
        DatabaseConnection* connection;
        bool in_use;
        std::chrono::steady_clock::time_point last_used;
        std::chrono::steady_clock::time_point created;
    };

    std::vector<PooledConnection> connections_;
    std::mutex pool_mutex_;
    std::condition_variable pool_cv_;
    size_t max_connections_;
    std::chrono::seconds connection_timeout_;

    DatabaseConnection* acquire_connection() {
        std::unique_lock<std::mutex> lock(pool_mutex_);

        // Wait for available connection
        pool_cv_.wait(lock, [this]() {
            return std::any_of(connections_.begin(), connections_.end(),
                             [](const PooledConnection& conn) {
                                 return !conn.in_use;
                             }) || connections_.size() < max_connections_;
        });

        // Find available connection
        for (auto& pooled_conn : connections_) {
            if (!pooled_conn.in_use) {
                pooled_conn.in_use = true;
                pooled_conn.last_used = std::chrono::steady_clock::now();
                return pooled_conn.connection;
            }
        }

        // Create new connection if under limit
        if (connections_.size() < max_connections_) {
            auto* conn = create_new_connection();
            connections_.push_back({conn, true, std::chrono::steady_clock::now(),
                                  std::chrono::steady_clock::now()});
            return conn;
        }

        return nullptr; // Should not reach here due to wait condition
    }

    void release_connection(DatabaseConnection* conn) {
        std::unique_lock<std::mutex> lock(pool_mutex_);

        for (auto& pooled_conn : connections_) {
            if (pooled_conn.connection == conn) {
                pooled_conn.in_use = false;
                pooled_conn.last_used = std::chrono::steady_clock::now();
                break;
            }
        }

        pool_cv_.notify_one();
    }
};
```

### **4. Write-Ahead Logging (WAL)**
```cpp
class WriteAheadLog {
    struct LogEntry {
        LogSequenceNumber lsn;
        TransactionId transaction_id;
        OperationType operation;
        std::string table_name;
        std::string key;
        std::string old_value;
        std::string new_value;
        std::chrono::system_clock::time_point timestamp;
    };

    std::vector<LogEntry> log_buffer_;
    std::ofstream log_file_;
    std::mutex log_mutex_;
    LogSequenceNumber next_lsn_;
    size_t buffer_size_;

    LogSequenceNumber log_operation(TransactionId tx_id, OperationType op,
                                  const std::string& table, const std::string& key,
                                  const std::string& old_val, const std::string& new_val) {
        std::unique_lock<std::mutex> lock(log_mutex_);

        LogEntry entry{
            next_lsn_++, tx_id, op, table, key, old_val, new_val,
            std::chrono::system_clock::now()
        };

        log_buffer_.push_back(entry);

        // Flush buffer if full
        if (log_buffer_.size() >= buffer_size_) {
            flush_buffer();
        }

        return entry.lsn;
    }

    void flush_buffer() {
        for (const auto& entry : log_buffer_) {
            log_file_ << serialize_entry(entry) << "\n";
        }
        log_file_.flush();
        log_buffer_.clear();
    }

    void recover_from_log() {
        // Read log file and replay operations
        std::ifstream log_stream(log_file_path_);
        std::string line;

        while (std::getline(log_stream, line)) {
            auto entry = deserialize_entry(line);
            replay_operation(entry);
        }
    }
};
```

## ğŸ¯ **Advanced Database Patterns**

### **1. Database Sharding with Consistent Hashing**
```cpp
class ConsistentHashRing {
    std::map<size_t, ShardId> ring_;
    std::unordered_map<ShardId, ShardInfo> shards_;
    size_t virtual_nodes_per_shard_;

    ShardId get_shard(const std::string& key) {
        size_t hash = hash_function(key);
        auto it = ring_.lower_bound(hash);

        if (it == ring_.end()) {
            return ring_.begin()->second;
        }

        return it->second;
    }

    void add_shard(ShardId shard_id) {
        shards_[shard_id] = ShardInfo{shard_id, 0, 0}; // capacity, load

        for (size_t i = 0; i < virtual_nodes_per_shard_; ++i) {
            size_t virtual_hash = hash_function(shard_id + "_" + std::to_string(i));
            ring_[virtual_hash] = shard_id;
        }
    }

    std::vector<ShardId> get_responsible_shards(const std::string& key, size_t replication_factor) {
        std::set<ShardId> responsible_shards;
        size_t hash = hash_function(key);

        auto it = ring_.lower_bound(hash);
        if (it == ring_.end()) {
            it = ring_.begin();
        }

        for (size_t i = 0; i < replication_factor && !ring_.empty(); ++i) {
            responsible_shards.insert(it->second);
            ++it;
            if (it == ring_.end()) {
                it = ring_.begin();
            }
        }

        return std::vector<ShardId>(responsible_shards.begin(), responsible_shards.end());
    }
};
```

### **2. Multi-Version Concurrency Control (MVCC)**
```cpp
class MVCCStorage {
    struct VersionedRecord {
        RecordId record_id;
        TransactionId transaction_id;
        Timestamp begin_timestamp;
        Timestamp end_timestamp;  // INF if current version
        std::string data;
        VersionedRecord* next_version;
    };

    std::unordered_map<RecordId, VersionedRecord*> records_;
    std::unordered_map<TransactionId, Transaction> active_transactions_;

    VersionedRecord* read_record(RecordId record_id, TransactionId tx_id) {
        auto* version = records_[record_id];

        // Find the version visible to this transaction
        while (version) {
            if (version->begin_timestamp <= tx_id &&
                (version->end_timestamp > tx_id || version->end_timestamp == INF)) {
                return version;
            }
            version = version->next_version;
        }

        return nullptr;
    }

    void write_record(RecordId record_id, const std::string& data, TransactionId tx_id) {
        // Create new version
        auto* new_version = new VersionedRecord{
            record_id, tx_id, tx_id, INF, data, nullptr
        };

        // Find current version and update its end timestamp
        auto* current = records_[record_id];
        if (current) {
            current->end_timestamp = tx_id;
            new_version->next_version = current;
        }

        records_[record_id] = new_version;
    }

    void commit_transaction(TransactionId tx_id) {
        // Update begin timestamps for all writes in this transaction
        for (auto& [record_id, version] : records_) {
            if (version->transaction_id == tx_id) {
                version->begin_timestamp = get_commit_timestamp(tx_id);
            }
        }
    }
};
```

### **3. Distributed Consensus with Raft**
```cpp
class RaftConsensus {
    enum class NodeState { FOLLOWER, CANDIDATE, LEADER };

    struct LogEntry {
        Term term;
        Index index;
        std::string command;
        bool committed;
    };

    NodeState state_;
    Term current_term_;
    NodeId voted_for_;
    std::vector<LogEntry> log_;
    Index commit_index_;
    Index last_applied_;

    std::vector<NodeId> cluster_nodes_;
    std::unordered_map<NodeId, Index> next_index_;
    std::unordered_map<NodeId, Index> match_index_;

    void start_election() {
        state_ = NodeState::CANDIDATE;
        current_term_++;
        voted_for_ = local_node_id_;

        // Send RequestVote RPCs to all other nodes
        int votes = 1; // Vote for self

        for (const auto& node : cluster_nodes_) {
            if (node != local_node_id_) {
                auto response = send_request_vote(node, current_term_,
                                                last_log_index(), last_log_term());

                if (response.vote_granted) {
                    votes++;
                }
            }
        }

        // Check if we have majority
        if (votes > cluster_nodes_.size() / 2) {
            become_leader();
        }
    }

    void become_leader() {
        state_ = NodeState::LEADER;

        // Initialize leader state
        for (const auto& node : cluster_nodes_) {
            next_index_[node] = log_.size() + 1;
            match_index_[node] = 0;
        }

        // Send initial heartbeats
        send_heartbeats();
    }

    void replicate_log_entry(const std::string& command) {
        if (state_ != NodeState::LEADER) return;

        // Append to local log
        LogEntry entry{current_term_, log_.size() + 1, command, false};
        log_.push_back(entry);

        // Replicate to followers
        for (const auto& node : cluster_nodes_) {
            if (node != local_node_id_) {
                send_append_entries(node);
            }
        }
    }
};
```

## ğŸ“š **Further Reading**

- **"Database System Concepts"** - Abraham Silberschatz, Henry F. Korth
- **"Transaction Processing: Concepts and Techniques"** - Jim Gray, Andreas Reuter
- **"Designing Data-Intensive Applications"** - Martin Kleppmann
- **"Database Internals"** - Alex Petrov
- **"Seven Databases in Seven Weeks"** - Eric Redmond, Jim R. Wilson
- **"High Performance MySQL"** - Baron Schwartz et al.
- **"PostgreSQL 14 Internals"** - Egor Rogov
- **"MongoDB: The Definitive Guide"** - Kristina Chodorow
- **"Cassandra: The Definitive Guide"** - Jeff Carpenter, Eben Hewitt

---

*"Database patterns are the foundation of data-driven systems - master them and you master the data itself."* ğŸ—„ï¸âš¡
